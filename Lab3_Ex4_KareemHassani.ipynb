{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO361xCLQPiFP9RuXQSpSpy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"M6YOe2WdhISk"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","import torchvision.transforms as transforms\n","from torchvision.datasets import ImageFolder\n","import matplotlib.pyplot as plt\n","\n","directory_train = r\"PATH train\" #REPLACE WITH YOUR PATHS\n","directory_val = r\"PATH VAL\"\n","directory_test = r\"PATH TEST\"\n"]},{"cell_type":"code","source":["\n","transform = transforms.Compose([transforms.Resize((128, 128)),  transforms.ToTensor()])\n","\n","class MyDataSet(Dataset):\n","    def __init__(self, directoryOfDataset, transform=None):\n","        self.data = ImageFolder(directoryOfDataset, transform=transform)\n","\n","    def __getitem__(self, index):\n","        return self.data[index]\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","class CNN_FF(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5) # 3 * 128 * 128 => conv1 :6 * 124 * 124 => pool: 6 * 62 * 62 => conv2: 16*58*58 => pool2: 16*29*29\n","        self.pool = nn.MaxPool2d(2, 2) #\n","        self.conv2 = nn.Conv2d(6, 16, 5) #\n","        self.fc1 = nn.Linear(16*29*29, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 53)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = torch.flatten(x, 1)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n"],"metadata":{"id":"EDCnI7TnkvZm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","dataset_train = MyDataSet(directory_train, transform=transform)\n","dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n","\n","dataset_val = MyDataSet(directory_val, transform=transform)\n","dataloader_val = DataLoader(dataset_val, batch_size=32, shuffle=False)\n","dataset_test = MyDataSet(directory_test, transform=transform)\n","dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=False)\n","\n","\n","model = CNN_FF()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.1)\n","\n","epochs = 10\n","for epoch in range(epochs):\n","    model.train()\n","    running_loss = 0\n","\n","    for images, labels in dataloader_train:\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","    print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(dataloader_train):.4f}')\n","\n","def evaluate_model(loader):\n","    model.eval()\n","    total, correct = 0, 0\n","    with torch.no_grad():\n","        for images, labels in loader:\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    return correct / total\n","\n","\n","val_accuracy = evaluate_model(dataloader_val)\n","print(f'Validation Accuracy: {val_accuracy * 100:.2f}%')\n","\n","test_accuracy = evaluate_model(dataloader_test)\n","print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n"],"metadata":{"id":"ThauZRBckyUo"},"execution_count":null,"outputs":[]}]}